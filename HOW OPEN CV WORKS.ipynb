{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0753187",
   "metadata": {},
   "source": [
    "### Getting Started with Images\n",
    "\n",
    "#### Goals:\n",
    "    #### Read an image from file (using cv::imread)\n",
    "    #### Display an image in an OpenCV window (using cv::imshow)\n",
    "    #### Write an image to a file (using cv::imwrite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8f0ee1",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\utils\\samples.cpp:64: error: (-2:Unspecified error) OpenCV samples: Can't find required data file: starry_night.jpg in function 'cv::samples::findFile'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a2c8189bbbc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"starry_night.jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\core\\src\\utils\\samples.cpp:64: error: (-2:Unspecified error) OpenCV samples: Can't find required data file: starry_night.jpg in function 'cv::samples::findFile'\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "import sys\n",
    "\n",
    "img = cv.imread(cv.samples.findFile(\"starry_night.jpg\"))\n",
    "\n",
    "if img is None:\n",
    "    sys.exit(\"Could not read the image\")\n",
    "    \n",
    "cv.imshow(\"Display window\", img)\n",
    "k  = cv.waitKey(0)\n",
    "\n",
    "if k == ord(\"s\"):\n",
    "    cv.imwrite(\"starry_night.png\", img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4730a624",
   "metadata": {},
   "source": [
    "### Getting Started with Videos\n",
    "\n",
    "#### Goals:\n",
    "    #### Learn to read video, display video and save video\n",
    "    #### Learn to capture video from a camera and dispalay it\n",
    "    #### You will learn these function cv.VideoCapture(), cv.VideoWriter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4543c797",
   "metadata": {},
   "source": [
    "* Capture video from a camera, you need to create a VideoCapture object. \n",
    "* Its argument can be either the device index or the name ofa video file.\n",
    "* A device index is just a the number to specific which camera, normall one camera will be connected, so simply passs 0 (or -1)\n",
    "* You can select the second camera by passing 1 and so on, after that you can capture frame by frame\n",
    "* DONT FORGET TO RELEASE THE CAPTURE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdd36e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "while True:\n",
    "    \n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # if frame is read correctly ret is TRUE\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting...\")\n",
    "        break\n",
    "    \n",
    "    # Our operations on the frame come here\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Display the resulting frame\n",
    "    cv.imshow('frame', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb21080",
   "metadata": {},
   "source": [
    "#### Playing Video from file\n",
    "\n",
    "* Playing video from file is the same as captruing it from camera, just change the camera index to a video file name\n",
    "* Also while displaying the frame, use appropriate time for cv.waitKey(). If it is too less, video will be very fast\n",
    "* If it is too high, video will be slow\n",
    "* 25 miliseconds will be okay in normal cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aa3a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture('vtest.avi')\n",
    "\n",
    "while cap, isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # if frame is read corrrectly ret is True\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting...\")\n",
    "        break\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    cv.imshow('frame', gray)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e98669",
   "metadata": {},
   "source": [
    "### Saving a Video\n",
    "\n",
    "* to capture a video frame by frame we create a VideoWriter object\n",
    "* Specify the output file name\n",
    "* Specify the FourCC code, then the number of frames per second (fps) and frame size\n",
    "* Last is the isColor flag, if True color, otherwise greyscale\n",
    "\n",
    "FourCC code is passed as cv.VideoWriter_fourcc('M','J','P','G') or cv.VideoWriter_fourcc(*'MJPG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3201f2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv.VideoWriter_fourcc(*'XVID')\n",
    "out = cv.VideoWriter('output.avi', fourcc, 20.0, (640, 480))\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Cant recevie frame (stream end?). Exiting...\")\n",
    "        break\n",
    "    frame = cv.flip(frame, 0)\n",
    "    \n",
    "    # write the flipped frame\n",
    "    out.write(frame)\n",
    "    \n",
    "    cv.imshow('frame', frame)\n",
    "    if cv.waitKey(1) == ord('q'):\n",
    "        break\n",
    "        \n",
    "# Release everything if the job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f92f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Cascde Classifier\n",
    "\n",
    "* how the Haar cascade object detection works\n",
    "* beasics of face detection and eye detection using Haar-Feature based Cascade Classifiers\n",
    "* use cv::CasCadeClassifier class to detect objects in a video stream\n",
    "            particularly will use these functions\n",
    "                * cv:CascadeClassifier::load to load a .xml classifier file, can be Harr or LBP classifier\n",
    "                * cv::CascadeClassifier::detectMultiScale to perform the detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bbce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenCV provides a training method (see Cascade Classifier Training) or pretrained models, that can be read using the cv::CascadeClassifier::load method. The pretrained models are located in the data folder in the OpenCV installation or can be found here.\n",
    "                https://github.com/opencv/opencv/tree/4.x/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a950900b",
   "metadata": {},
   "source": [
    "Haar-cascade Detection in OpenCV\n",
    "\n",
    "* First, a cv::CascadeClassifier is created and the necessary XML file is loaded using the cv::CascadeClassifier::load method\n",
    "* Afterwards, the detection is done using cv::CascadeClassifier::detectMultiScale method, which returns boundary rectangles for face and eyes\n",
    "\n",
    "\n",
    "tutorial - https://github.com/opencv/opencv/blob/4.x/samples/python/tutorial_code/objectDetection/cascade_classifier/objectDetection.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81793f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2 as cv\n",
    "import argparse\n",
    "\n",
    "def detectAndDisplay(frame):\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv.equalizeHist(frame_gray)\n",
    "    \n",
    "    #-- Detect faces\n",
    "    faces = face_cascade.detectMultiScale(frame_gray)\n",
    "    for (x,y,w,h) in faces:\n",
    "        center = (x + w//2, y + h//2)\n",
    "        frame = cv.ellipse(frame, center, (w//2, h//2), 0, 0, 360, (255, 0, 255), 4)\n",
    "        \n",
    "        faceROI = frame_gray[y:y+h, x:x+w]\n",
    "        #-- In each face, detect eyes\n",
    "        eyes = eyes_cascade.detectMultiScale(faceROI)\n",
    "        for (x2,y2,w2,h2) in eyes:\n",
    "                eye_center = (x + x2 + w2//2, y + y2 + h2//2)\n",
    "                radius = int(round((w2 +h2)*0.25))\n",
    "                frame = cv.circle(frame, eye_center, radius, (255, 0, 0 ), 4)\n",
    "    \n",
    "    cv.imshow('Capture - Face detection', frame)\n",
    "    \n",
    "parser = argparse.ArgumentParser(description='Code for Cascade Classifier tutorial.')\n",
    "parser.add_argument('--face_cascade', help='Path to face cascade.', default='data/haarcascades/haarcascade_frontalface_alt.xml'\n",
    "parser.add_argument('--eyes_cascade', help='Path to eyes cascade.', default='data/haarcascades/haarcascades_eye_tree_eyeglasses.xml')\n",
    "parser.add_argument('--camera', help='Camera divide number.', type=int, default=0)\n",
    "args = parser.parse_args()\n",
    "                    \n",
    "face_cascade_name = args.face_cascade\n",
    "eyes_cascade_name = args.eyes_cascade\n",
    "                    \n",
    "face_cascade = cv.CascadeClassifier()\n",
    "eyes_cascade = cv.CascadeClassifier()\n",
    "                    \n",
    "#-- 1. Load the cascades\n",
    "if not face_cascade.load(cv.samples.findFile(face_cascade_name)):\n",
    "    print('--(!)Error loading face cascade')\n",
    "    exit(0)\n",
    "if not eyes_cascade.load(cv.samples.findFile(eyes_cascade_name)):\n",
    "    print('--(!)Error loading eyes cascade')\n",
    "    exit(0)\n",
    "\n",
    "camera_device = args.camera\n",
    "#-- 2. Read the video stream\n",
    "cap = cv.VideoCapture(camera_device)\n",
    "if not cap.isOpened:\n",
    "        print('--(!)Error opening video capture')\n",
    "        exit(0)\n",
    "                    \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        print('--(!) No captured frame -- Break!')\n",
    "        break\n",
    "                    \n",
    "    detectAndDisplay(frame)\n",
    "                    \n",
    "    of cv.waitKey(10) == 27:\n",
    "        break\n",
    "                    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb55508",
   "metadata": {},
   "source": [
    "* Be sure the program will find the path of files haarcascade_frontalface_alt.xml and haarcascade_eye_tree_eyeglasses.xml. \n",
    "* They are located in opencv/data/haarcascades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40497246",
   "metadata": {},
   "source": [
    "#### How OpenCV-Python Bindings Work\n",
    "\n",
    "* How OpenCV-Python bindings are generated\n",
    "* How to extend new OpenCV modules to python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e290a61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OpenCV generates these wrapper functions automatically from the C++ headers using some Python scripts which are located in modules/python/src2. \n",
    "We will look into what they do."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
